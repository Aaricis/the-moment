import json
import os
import sys

sys.path.append(os.path.split(sys.path[0])[0])  # æ·»åŠ åŒ…æœç´¢è·¯å¾„
import textwrap

import requests
import torch
from dotenv import load_dotenv
from loguru import logger
from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer

from src.configs.tts_config import audio_path, slicer_list
from src.utils.loader import load_text_audio_mappings

from generate import async_chat
from src.configs.base_config import model_path
from src.configs.rag_config import prompt_template
from src.rag.pipeline import EmoLLMRAG
import gradio as gr
import base64
from pathlib import Path

from src.asr.asr import whisper_recognize

load_dotenv()  # è‡ªåŠ¨æŠŠ .env è¯»å…¥ç¯å¢ƒå˜é‡

LANGSEARCH_API_URL = "https://api.langsearch.com/v1/web-search"
LANGSEARCH_API_KEY = os.getenv('LANGSEARCH_API_KEY')


def lang_search(query, max_results=5):
    """
    è”ç½‘æœç´¢
    :param query: ç”¨æˆ·é—®é¢˜
    :param max_results: è¿”å›ç»“æœæ•°é‡
    :return: æœç´¢ç»“æœ
    """
    payload = json.dumps({
        "query": query,
        "freshness": "noLimit",
        "summary": True,
        "count": max_results
    })

    headers = {
        "Authorization": f"Bearer {LANGSEARCH_API_KEY}",
        "Content-Type": "application/json"
    }

    response = requests.post(LANGSEARCH_API_URL, headers=headers, data=payload)
    if response.status_code == 200:
        logger.info("Response Success: 200")
        results = json.loads(response.text).get("data").get("webPages").get("value")
        search_results = []
        for result in results:
            title = result.get("name", "")
            snippet = result.get("snippet", "")
            url = result.get("url", "")
            search_results.append(f"æ ‡é¢˜ï¼š{title}\næ‘˜è¦ï¼š{snippet}\né“¾æ¥ï¼š{url}\n")
        return "\n".join(search_results)
    else:
        logger.error(f"Response Error: {response.status_code}")
        return ""


@torch.inference_mode()
async def generate_response_and_tts(
        history,
        temperature,
        top_p,
        max_new_tokens,
        repetition_penalty,
        active_gen,
        selected_text,
        ref_text,
        prompt_language,
        text_language,
        how_to_cut
):
    print("history len =", len(history), "history =", history)
    print(f"type = {type(history)}")

    # è·å–ç”¨æˆ·æ¶ˆæ¯ï¼ˆå€’æ•°ç¬¬äºŒæ¡ï¼‰
    user_message = history[-2]["content"]
    print(f"user_message = {user_message}")

    conversation = []
    # éå†é™¤æœ€åä¸¤æ¡ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯
    for msg in history[:-2]:
        if msg.get("content") and msg.get("content").strip():  # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
            conversation.append({
                "role": msg.get("role", "user"),  # é»˜è®¤è§’è‰²ä¸ºuser
                "content": msg.get("content", "")
            })

    # è”ç½‘æœç´¢
    searched_results = lang_search(user_message)
    if searched_results:
        logger.info(f"è”ç½‘æœç´¢ç»“æœï¼š{searched_results}")
    else:
        logger.info("è”ç½‘æœªæœç´¢åˆ°å‡†ç¡®ä¿¡æ¯")

    # çŸ¥è¯†åº“æœç´¢
    rag = EmoLLMRAG()
    retrieved_context = rag.get_retrieval_content(user_message)
    if retrieved_context:
        logger.info(f"çŸ¥è¯†åº“æœç´¢ç»“æœï¼š{retrieved_context}")
    else:
        logger.info("çŸ¥è¯†åº“æœªæœç´¢åˆ°å‡†ç¡®ä¿¡æ¯")

    conversation.append(
        {
            "role": "user",
            "content": textwrap.dedent(prompt_template).format(
                user_input=user_message,
                searched_results=searched_results,
                retrieved_context=retrieved_context
            )
        }
    )

    input_ids = tokenizer.apply_chat_template(
        conversation,
        tokenize=True,  # ç›´æ¥è¾“å‡º token
        add_generation_prompt=True,  # åœ¨ç»“å°¾åŠ ä¸Šâ€œAssistant å¼€å§‹å›ç­”â€çš„æç¤ºï¼Œè®©æ¨¡å‹è¿›å…¥ç”Ÿæˆæ¨¡å¼
        return_tensors="pt"  # ç›´æ¥è¿”å› PyTorch tensor
    ).to(model.device)

    streamer = TextIteratorStreamer(  # æµå¼è¾“å‡º
        tokenizer,
        timeout=20.0,
        skip_prompt=True,  # ä¸è¿”å› prompt æ–‡æœ¬ï¼ˆåªè¾“å‡ºæ¨¡å‹ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
        skip_special_tokens=True  # æ»¤æ‰ç‰¹æ®Šç¬¦å·<endoftext>, <pad>
    )

    generate_kwargs = dict(
        input_ids=input_ids,
        streamer=streamer,
        temperature=temperature,
        top_p=top_p,
        repetition_penalty=repetition_penalty,
        do_sample=True,
        max_new_tokens=max_new_tokens,
        tokenizer=tokenizer,
    )

    async for history, audio, conversion_time in async_chat(
            active_gen,
            history,
            tokenizer,
            model,
            generate_kwargs,
            selected_text,
            ref_text,
            prompt_language,
            text_language,
            how_to_cut
    ):
        yield history, audio, conversion_time


# åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥å¤„ç†æµå¼è¾“å‡º
async def generate_wrapper(
        chatbot,
        temperature,
        top_p,
        max_new_tokens,
        repetition_penalty,
        active_gen,
        selected_text,
        ref_text,
        prompt_language,
        text_language,
        how_to_cut
):
    async for chatbot, audio, tts_time in generate_response_and_tts(
            chatbot,
            temperature,
            top_p,
            max_new_tokens,
            repetition_penalty,
            active_gen,
            selected_text,
            ref_text,
            prompt_language,
            text_language,
            how_to_cut
    ):

        # å¦‚æœæ˜¯ä¸­é—´ç»“æœï¼Œåªæ›´æ–°chatbot
        if audio is None:
            # æ–‡æœ¬æµ
            yield chatbot, None, None
        else:
            # éŸ³é¢‘æµ
            yield chatbot, audio, tts_time


def build_app():
    assets_dir = Path(__file__).parent.parent / "assets"
    bg_path = str(assets_dir / "bg.jpg")

    with open(bg_path, "rb") as f:
        bg_base64 = base64.b64encode(f.read()).decode()

    css = f"""
    html, body {{
        height: 100%;
        margin: 0;
        background: linear-gradient(rgba(18,18,18,0.6), rgba(18,18,18,0.6)),
                    url("data:image/jpg;base64,{bg_base64}") no-repeat center center fixed;
        background-size: cover;
        font-family: 'Inter', sans-serif;
        color: #e5e7eb;
    }}
    .container {{
        backdrop-filter: blur(18px);
        -webkit-backdrop-filter: blur(18px);
        background: rgba(255,255,255,0.07);
        border-radius: 20px;
        border: 1px solid rgba(255,255,255,0.15);
        box-shadow: 0 8px 40px rgba(0,0,0,0.4);
        padding: 28px;
        margin: 40px auto;
        max-width: 950px;
    }}
    .app-title {{
        text-align: center;
        font-size: 2.2rem;
        font-weight: 700;
        color: #facc15;
        margin-bottom: 6px;
        text-shadow: 0 0 10px rgba(250,204,21,0.6);
    }}
    .subtitle {{
        text-align: center;
        color: #9ca3af;
        font-size: 1rem;
        margin-bottom: 20px;
    }}
    #chatbot {{
        background: rgba(255,255,255,0.06);
        border-radius: 16px;
        padding: 18px;
        height: 520px !important;
        overflow-y: auto;
        border: 1px solid rgba(255,255,255,0.2);
        box-shadow: inset 0 0 20px rgba(0,0,0,0.25);
    }}
    .section {{
        margin-top: 20px;
        margin-bottom: 12px;
    }}
    """

    def user(message, history):
        """å°†ç”¨æˆ·æ¶ˆæ¯åŠ å…¥èŠå¤©å†å²"""
        if not message:
            return "", history
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": ""})
        return "", history

    with gr.Blocks(css=css, title="The Moment") as demo:
        with gr.Column(elem_classes="container"):
            # ===== æ ‡é¢˜ =====
            gr.HTML("<div class='app-title'>âœ¨ The Moment âœ¨</div>")
            gr.HTML("<div class='subtitle'>AI æƒ…æ„Ÿé™ªä¼´ Â· ä¸­æ–‡è¯­éŸ³è¯†åˆ« + æ™ºèƒ½å¯¹è¯</div>")

            # ===== èŠå¤©çª—å£ =====
            chatbot = gr.Chatbot(
                elem_id="chatbot",
                height=520,
                show_label=False,
                render_markdown=True,
                type="messages",
                show_copy_button=True,
            )

            # ===== è¾“å…¥åŒºï¼šæ–‡å­— + è¯­éŸ³ å¹¶åˆ— =====
            gr.HTML("<div class='section'><b>ğŸ’¬ è¾“å…¥æ–‡å­—æˆ–è¯­éŸ³è¿›è¡Œäº¤æµ</b></div>")
            with gr.Row(equal_height=True):
                # å·¦ä¾§ï¼šæ–‡å­—è¾“å…¥æ¡† + å‘é€æŒ‰é’®
                with gr.Column(scale=3):
                    msg = gr.Textbox(
                        placeholder="ğŸ“ è¾“å…¥æ–‡å­—å†…å®¹...",
                        lines=2,
                        scale=3
                    )
                    submit_btn = gr.Button("ğŸš€ å‘é€æ–‡å­—", variant='primary')

                # å³ä¾§ï¼šè¯­éŸ³å½•åˆ¶ + è¯†åˆ«æŒ‰é’®
                with gr.Column(scale=2):
                    mic = gr.Audio(
                        sources=["microphone"],
                        type="numpy",
                        label="ğŸ¤ è¯­éŸ³å½•åˆ¶",
                    )
                    voice_to_text_btn = gr.Button("ğŸ§ è½¬æ–‡å­—", variant='secondary')

            # ===== ç¤ºä¾‹è¯é¢˜ =====
            gr.HTML("<div class='section'><b>ğŸ’¡ ç¤ºä¾‹è¯é¢˜</b></div>")
            gr.Examples(
                examples=[
                    ["æœ€è¿‘å‹åŠ›å¾ˆå¤§ï¼Œæ€»æ˜¯ç¡ä¸å¥½ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ"],
                    ["æˆ‘å’Œçˆ¶æ¯æ€»æ˜¯æ²Ÿé€šä¸é¡ºï¼Œä»–ä»¬æ€»è§‰å¾—æˆ‘ä¸æ‡‚äº‹ã€‚"],
                    ["æˆ‘å®³æ€•å¤±è´¥ï¼Œæ€»è§‰å¾—è‡ªå·±ä¸å¤Ÿå¥½ã€‚"],
                    ["æˆ‘å–œæ¬¢ä¸€ä¸ªäººï¼Œä½†ä¸æ•¢è¡¨ç™½ã€‚"],
                    ["æ€ä¹ˆæ‰èƒ½è®©è‡ªå·±æ›´æœ‰è‡ªä¿¡ï¼Ÿ"]
                ],
                inputs=msg,
            )

            # ===== å‚æ•°è®¾ç½® =====
            gr.HTML("<div class='section'><b>âš™ï¸ æ¨¡å‹å‚æ•°è®¾ç½®</b></div>")
            with gr.Accordion("ç”Ÿæˆå‚æ•°è°ƒæ•´", open=False):
                with gr.Row():
                    temperature = gr.Slider(0.1, 1.5, 0.6, label="Temperature")
                    top_p = gr.Slider(0.1, 1.0, 0.95, label="Top-p")
                with gr.Row():
                    max_new_tokens = gr.Slider(2048, 32768, 4096, step=64, label="Max Tokens")
                    repetition_penalty = gr.Slider(1, 1.5, 1.2, step=0.01, label="Repetition Penalty")

            # ===== è¯­éŸ³è¾“å‡º =====
            gr.HTML("<div class='section'><b>ğŸ”Š è¯­éŸ³è¾“å‡º</b></div>")
            with gr.Row():
                output_audio = gr.Audio(label="æ¨¡å‹è¯­éŸ³å›åº”", streaming=True, autoplay=True)
                tts_time_display = gr.Textbox(label="TTS ç”¨æ—¶", value="0s", interactive=False)

            # ===== æ§åˆ¶æŒ‰é’® =====
            with gr.Row():
                clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºå¯¹è¯", variant='secondary')
                stop_btn = gr.Button("â¹ åœæ­¢ç”Ÿæˆ", variant='stop')

            # ===== æ¨¡å‹é€»è¾‘ =====
            active_gen = gr.State([False])

            text_to_audio_mappings = load_text_audio_mappings(audio_path, slicer_list)
            default_audio_select = list(text_to_audio_mappings.keys())[0] if text_to_audio_mappings else ""
            default_ref_text = default_audio_select
            default_prompt_language = "zh"
            default_text_language = "zh"
            default_how_to_cut = "æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡"

            # === æ–‡å­—è¾“å…¥äº‹ä»¶ ===
            submit_event = submit_btn.click(
                user, [msg, chatbot], [msg, chatbot], queue=False
            ).then(
                lambda: [True], outputs=active_gen
            ).then(
                generate_wrapper,
                [
                    chatbot, temperature, top_p, max_new_tokens, repetition_penalty, active_gen,
                    gr.State(default_audio_select), gr.State(default_ref_text),
                    gr.State(default_prompt_language), gr.State(default_text_language),
                    gr.State(default_how_to_cut)
                ],
                [chatbot, output_audio, tts_time_display]
            )

            # === è¯­éŸ³è¯†åˆ«äº‹ä»¶ ===
            voice_to_text_btn.click(
                fn=whisper_recognize,  # è¯­éŸ³è½¬æ–‡å­—
                inputs=mic,
                outputs=msg,
                show_progress=True
            )

            # === æ§åˆ¶æŒ‰é’® ===
            stop_btn.click(lambda: [False], None, active_gen, cancels=[submit_event])
            clear_btn.click(lambda: (None, None, "0s"), None,
                            [chatbot, output_audio, tts_time_display],
                            queue=False).then(lambda: [False], None, active_gen,
                                              cancels=[submit_event])

    return demo


if __name__ == "__main__":
    logger.info("Loading Deepseek-R1 model...")

    # åŠ è½½æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    )

    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    tokenizer.use_default_system_prompt = False  # å…³é—­ tokenizer è‡ªåŠ¨åœ¨å¯¹è¯æœ€å‰é¢è¿½åŠ ã€Œç³»ç»Ÿé»˜è®¤æç¤ºè¯ã€çš„è¡Œä¸º

    app = build_app()
    app.queue(api_open=True, max_size=20, default_concurrency_limit=20).launch(server_name="0.0.0.0", server_port=7860,
                                                                               max_threads=40)
