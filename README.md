# ğŸ’—The Moment
**è°æ§åˆ¶ç°åœ¨å°±æ§åˆ¶è¿‡å»ï¼Œè°æ§åˆ¶è¿‡å»å°±æ§åˆ¶æœªæ¥ï¼The Momentæ˜¯ä¸€ä¸ªå…·æœ‰å¿ƒç†å­¦çŸ¥è¯†çš„AIåŠ©æ‰‹ï¼Œç†è§£å½“ä¸‹æ¯ä¸€åˆ»çš„ä½ ã€‚**  

ğŸ’•**Always be your side and never leave you alone!**

>_ä»€ä¹ˆæ˜¯äººç”Ÿé‡Œå…³é”®æ€§çš„ä¸€åˆ»ï¼Œ_
_æ˜¯ä¸€ä¸ªå†³å®šï¼›_  
_æ˜¯ä¸€æ¬¡é€‰æ‹©ï¼›_  
_æ˜¯å‘å·¦ï¼Œè¿˜æ˜¯å‘å³ï¼›_  
_æ˜¯ç»§ç»­ï¼Œæˆ–è€…æ”¾å¼ƒï¼›_  
_æ˜¯è·Ÿè¿‡å»å‘Šåˆ«çš„ä¸€åˆ»ï¼›_  
_æ˜¯å‹‡æ•¢æ“¦æ‹­ä¼¤å£çš„é‚£ä¸€åˆ»ï¼›_  
_æ˜¯æŠ‰æ‹©æœªæ¥çš„é‚£ä¸€åˆ»ã€‚_  
......

## ğŸš€é¡¹ç›®é¢„è§ˆ | Preview
### The Moment æ–‡å­—ç‰ˆ 

https://github.com/user-attachments/assets/a34a5cab-cf9e-47b3-a4e7-3ce1fefdd12a

**å®Œæ•´è§†é¢‘** [![å®Œæ•´æ¼”ç¤º](/assets/icon.png)](https://www.bilibili.com/video/BV1oY43zCE5x/?share_source=copy_web&vd_source=f27af9aa2b0a1efe2d357b9f461ba958)

### The Moment è¯­éŸ³ç‰ˆ

https://github.com/user-attachments/assets/bee2017b-37a8-45b1-876d-01828e358af6

**å®Œæ•´è§†é¢‘** [![å®Œæ•´æ¼”ç¤º](/assets/icon.png)](https://www.bilibili.com/video/BV1oY43zCEQK/?share_source=copy_web&vd_source=f27af9aa2b0a1efe2d357b9f461ba958)

## âœ¨åŠŸèƒ½ç‰¹æ€§ | Features
âœ… æä¾›å¤šè½®å¿ƒç†å’¨è¯¢äº’åŠ¨èŠå¤©æœåŠ¡ï¼›   
âœ… é›†æˆStructured Fine-Tuningã€Retrieval-augmented generation (RAG)å’Œç½‘ç»œæœç´¢ï¼Œä½¿Agentç»™å‡ºä¸“ä¸šçš„å›ç­”ï¼›   
âœ… é›†æˆ[Whisper](https://github.com/openai/whisper)å’Œ[GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)ï¼Œæä¾›è¯­éŸ³äº¤äº’åŠŸèƒ½ï¼›  
âœ… è¯­éŸ³è¾“å‡ºæ”¯æŒè‡ªå®šä¹‰éŸ³è‰²ï¼›  
âœ… ä»¥æµå¼æ–¹å¼ç”Ÿæˆæ–‡å­—å’Œè¯­éŸ³ï¼Œç”¨æˆ·ä½“éªŒè‡ªç„¶æµç•…ï¼›

## ğŸ°æŠ€æœ¯æ¶æ„ | Architecture

![å·¥ç¨‹æ¶æ„å›¾](/assets/the_moment_workflow.png)

The moment as a typical conversational AI application uses three subsystems to do the steps of processing and transcribing the audio, understanding (deriving meaning) of the question asked, generating the response (text) and speaking the response back to the human. These steps are achieved by multiple deep learning solutions working together. First, automatic speech recognition (ASR) is used to process the raw audio signal and transcribing text from it. Second, natural language processing (NLP) is used to derive meaning from the transcribed text (ASR output). Last, speech synthesis or text-to-speech (TTS) is used for the artificial production of human speech from text. Optimizing this multi-step process is complicated, as each of these steps requires building and using one or more deep learning models. When developing a deep learning model to achieve the highest performance and accuracy for each of these areas, a developer will encounter several approaches and experiments that can vary by domain application.

## ğŸ‘¨â€ğŸ’»å¿«é€Ÿå¼€å§‹ | Quick Start

1. å®‰è£…ç¯å¢ƒ | Install Environment

**Install Directly**

```text
pip install -r requirements.txt
```

**Install from conda**

```text
conda create -n <env name> python=3.11
conda activate <env name>
pip install -r requirements.txt
```

2. ä¸‹è½½æ¨¡å‹æƒé‡ | Download Model Weights
```bash
./scripts/download_weights.sh
```
3. å¯åŠ¨ Web UI | Run Web Interface
```bash
cd the_moment/tools
python webui_speech.py
```

## ğŸ’é¡¹ç›®ä¼˜åŒ– ï½œ TODO
- [ ] æ›´æ–°é—®ç­”æ¨¡å‹çŸ¥è¯†ï¼Œæˆ–ä½¿ç”¨æ›´åŠ ä¸“ä¸šçš„å¿ƒç†å­¦æ¨¡å‹ï¼›
- [ ] æ¨¡å‹æ¨ç†åŠ é€Ÿä¼˜åŒ–ï¼›
- [ ] æé«˜Text to Speech (TTS)è¯­éŸ³åˆæˆçš„è´¨é‡ï¼Œæ¶ˆé™¤åœé¡¿å’Œæ‚éŸ³ï¼›
- [ ] ä½¿ç”¨end-to-end Acoustic Modelï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„ASR->LLM->TTSæ¶æ„ï¼Œæ¶ˆé™¤ä¸å¿…è¦çš„æ—¶å»¶ï¼›

## ğŸ™Œå…è´£å£°æ˜ | Disclaimer

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚ä½¿ç”¨è€…é¡»éµå®ˆå½“åœ°çš„æ³•å¾‹æ³•è§„ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº DMCA ç›¸å…³æ³•å¾‹ã€‚æˆ‘ä»¬ä¸å¯¹ä»»ä½•éæ³•ä½¿ç”¨æ‰¿æ‹…è´£ä»»ã€‚

This project is for research and learning purposes only. Users must comply with local laws and regulations, including but not limited to DMCA-related laws. We do not take any responsibility for illegal usage.

## ğŸ™‡æŠ€æœ¯é¸£è°¢ | Credits

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å¼€æºé¡¹ç›®æ„å»ºï¼š

- [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
- [Whisper](https://github.com/openai/whisper)
